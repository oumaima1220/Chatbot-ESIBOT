{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08ddef7f",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad1ad6d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hp\\anaconda3\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import tensorflow as tf\n",
    "import pickle \n",
    "import string\n",
    "import tflearn\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897e3b18",
   "metadata": {},
   "source": [
    "### Importing json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72d58ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tag : Welcome: \n",
      "Pattern :['Hello', 'Hi', 'Hi there', 'Hello there', 'Good evening', \"Hello, I'm a new student, I have some questions, please!\", 'Hi, I have some questions for you']: \n",
      "Response :['Great! Hi! How can I help?', 'Good! Hi, how can I help you?', \"Welcome to our school! I'm here to help you. How can I assist you?\", \"Hello! I'm here to assist you. How can I help you?\", \"Welcome! I'm here to assist you. What specific information are you looking for?\"] \n",
      "\n",
      "Tag : CourtesyGreeting: \n",
      "Pattern :['How are you?', 'Hi how are you?', 'Hello how are you?', 'Hola how are you?', 'How are you doing?', 'Hope you are doing well?', 'Hello hope you are doing well?']: \n",
      "Response :['Hello, I am great, how are you?', 'Hello, how are you? I am great thanks!', 'Hello, I am good thank you, how are you?', 'Hi, I am great, how are you?', 'Hi, how are you? I am great thanks!', 'Hi, I am good thank you, how are you?', 'Hi, good thank you, how are you?'] \n",
      "\n",
      "Tag : Name: \n",
      "Pattern :['What is your name?', 'What could I call you?', 'What can I call you?', 'What do your friends call you?', 'Who are you?', 'Tell me your name?']: \n",
      "Response :['You can call me Esibot', 'You may call me Esibot', 'Call me Esibot'] \n",
      "\n",
      "Tag : Thanks: \n",
      "Pattern :['OK thank you', 'OK thanks', 'OK', 'Thanks', \"That's helpful\", 'Thank you!', 'Thanks for all the information!', 'Thanks for your assistance!', 'Thanks for your help!']: \n",
      "Response :['Happy to help!', 'Any time!', 'My pleasure', \"You're welcome. If you have more questions in the future, don't hesitate to contact us. Good luck with your studies!\", \"You're welcome! Have a productive day!\"] \n",
      "\n",
      "Tag : Understand: \n",
      "Pattern :['Do you understand what I am saying', 'Do you understand me', 'Do you know what I am saying', 'Do you get me', 'Do you know what I mean']: \n",
      "Response :['If you ever see that the information given is not relevant to your query, please try to rephrase your query and I would be happy to give you a more adequate answer'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Open the JSON file\n",
    "with open('Intentions_data_file.json', encoding='utf-8') as json_data:\n",
    "    intentions_data = json.load(json_data)\n",
    "\n",
    "# Get the 'intentions' list from the JSON data\n",
    "intentions_list = intentions_data.get('intentions', [])\n",
    "for index, intention in enumerate(intentions_list[:5]):\n",
    "    print(f\"Tag : {intention['tag']}: \\nPattern :{intention['patterns']}: \\nResponse :{intention['responses']} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14aad95e",
   "metadata": {},
   "source": [
    "### Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bf2439b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba9687dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba24ebf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Achievements', 'Administration', 'Awards', 'BookBorrowing', 'CSIOpportunities', 'CSIProgram', 'Certifications', 'Clubs', 'ClubsSocialMedia', 'CourtesyGreeting', 'DIE', 'DIEOpportunities', 'Doctorate', 'DoctorateApplication', 'DoctorateEligible', 'DoctorateFields', 'EngineeringSpecializations', 'EventTypes', 'Events', 'Exams', 'Feedback', 'Goodbye', 'IMOpportunities', 'IMProgram', 'ISDOpportunities', 'ISDT', 'ISSCD', 'ISSCDOpportunities', 'ITSupport', 'Invitations', 'KEDS', 'KEDSOpportunities', 'Library', 'LibraryHours', 'MECOHVOpportunities', 'MECOHVProgram', 'MasterFields', 'Name', 'Registration', 'Restaurant', 'Scholarships', 'SchoolSocialMedia', 'Specialization', 'Sport', 'StudyHours', 'Teachers', 'Thanks', 'Understand', 'Welcome']\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "stemmer = SnowballStemmer('english')  \n",
    "\n",
    "mots = [] \n",
    "classes = [] \n",
    "documents = [] \n",
    "\n",
    "for intention in intentions_data['intentions']:\n",
    "    for pattern in intention['patterns']:  \n",
    "\n",
    "        m = nltk.word_tokenize(pattern) \n",
    "        m = [u for u in m if u not in string.punctuation if u not in stop_words]\n",
    "        \n",
    "        mots.extend(m) \n",
    "\n",
    "        documents.append((m, intention['tag'])) \n",
    "        if intention['tag'] not in classes:\n",
    "            classes.append(intention['tag'])\n",
    "\n",
    "mots = [stemmer.stem((m.lower())) for m in mots]\n",
    "\n",
    "\n",
    "mots = sorted(list(set(mots))) \n",
    "classes = sorted(list(set(classes))) \n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059a4c14",
   "metadata": {},
   "source": [
    "### Creating data for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80d19eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = []\n",
    "output = []\n",
    "output_vide = [0] * len(classes) \n",
    "for doc in documents:\n",
    "    ensemble = []\n",
    "    pattern_mots = doc[0] \n",
    "    pattern_mots = [stemmer.stem(mot.lower()) for mot in pattern_mots] \n",
    "\n",
    "    for m in mots: \n",
    "        ensemble.append(1) if m in pattern_mots else ensemble.append(0)\n",
    "\n",
    "    output_row = list(output_vide) \n",
    "    \n",
    "    output_row[classes.index(doc[1])] = 1    \n",
    "\n",
    "    training.append([ensemble, output_row]) \n",
    "training = np.array(training) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae4c691",
   "metadata": {},
   "source": [
    "### Spliting training data into features and labels lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd9886a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = list(training[:, 0])\n",
    "train_y = list(training[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8ef771",
   "metadata": {},
   "source": [
    "### Model creation and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a62480b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 10999  | total loss: \u001b[1m\u001b[32m0.06550\u001b[0m\u001b[0m | time: 0.053s\n",
      "| Adam | epoch: 1000 | loss: 0.06550 - acc: 0.9699 -- iter: 80/84\n",
      "Training Step: 11000  | total loss: \u001b[1m\u001b[32m0.05921\u001b[0m\u001b[0m | time: 0.057s\n",
      "| Adam | epoch: 1000 | loss: 0.05921 - acc: 0.9729 -- iter: 84/84\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "# Reset the default graph\n",
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "# Define the model architecture\n",
    "net = tflearn.input_data(shape=[None, len(train_x[0])]) # input layer # len(train_x[0]) is the number of distinct words processed(features)\n",
    "\n",
    "# Fully connected layers with regularization\n",
    "net = tflearn.fully_connected(net, 8)\n",
    "net = tflearn.fully_connected(net, 8)\n",
    "# Output layer with softmax activation\n",
    "net = tflearn.fully_connected(net, len(train_y[0]), activation='softmax') # len(train_y[0]) is the number of labels(tags)\n",
    "net = tflearn.regression(net)\n",
    "\n",
    "# Create the mode\n",
    "model = tflearn.DNN(net, tensorboard_dir='tflearn_logs')\n",
    "# Fit the model\n",
    "model.fit(train_x, train_y, n_epoch=1000, batch_size=8, show_metric=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04bee397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:C:\\Users\\hp\\Downloads\\Projet Chatbot\\Chatbot_Esibot\\LastVersions\\model.teflearn is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    }
   ],
   "source": [
    "model.save('model.teflearn')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6dc1a30",
   "metadata": {},
   "source": [
    "### Preprocess for new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d62d1c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump({'mots': mots, 'classes': classes, 'train_x': train_x, 'train_y': train_y}, open(\"training_data\", 'wb'))\n",
    "\n",
    "data = pickle.load(open(\"training_data\", \"rb\"))\n",
    "\n",
    "mots = data['mots']\n",
    "classes = data['classes']\n",
    "train_x = data['train_x']\n",
    "train_y = data['train_y']\n",
    "with open('Intentions_data_file.json', encoding='utf-8') as json_data:\n",
    "    intentions_data = json.load(json_data)\n",
    "\n",
    "def traitement_expression(expression):\n",
    "    expression_mots = nltk.word_tokenize(expression)\n",
    "    expression_mots = [u for u in expression_mots if u not in string.punctuation if u not in stop_words]\n",
    "    expression_mots = [stemmer.stem(mot.lower()) for mot in expression_mots]\n",
    "    return expression_mots\n",
    "\n",
    "\n",
    "def ensemble_tab(expression, mots, show_details=False):\n",
    "    expression_mots = traitement_expression(expression)\n",
    "    ensemble = [0] * len(mots)\n",
    "    for e in expression_mots:\n",
    "        for i, m in enumerate(mots):\n",
    "            if m == e:\n",
    "                ensemble[i] = 1  \n",
    "                if show_details:\n",
    "                    print(\"it's found: %e\" % m)\n",
    "    return (np.array(ensemble))\n",
    "\n",
    "def classification(expression): \n",
    "    results = model.predict([ensemble_tab(expression, mots)])[0] \n",
    "    results = [[i, r] for i, r in enumerate(results)]\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    return_list = []\n",
    "    for r in results:\n",
    "        return_list.append((classes[r[0]], r[1]))\n",
    "    return return_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c9e09c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def response(expression, ID_Utilisateur='123', show_details=False):\n",
    "    results = classification(expression)\n",
    "    if results:\n",
    "        while results:\n",
    "            for i in intentions_data['intentions']: \n",
    "                if i['tag'] == results[0][0]:  \n",
    "                    return print('\\n',random.choice(i['responses']), \"\\n\")\n",
    "            results.pop(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb739eb",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4dd4df03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I am here to chat. if you need to go just enter \"quit\" :)\n",
      "You: Hi! I am a new student and I would like to ask you some questions, please!\n",
      "\n",
      " Welcome to our school! I'm here to help you. How can I assist you? \n",
      "\n",
      "You: I have just started my first year in Knowledge Engineering and Data Science, can you give me detailed information about training in this field?\n",
      "\n",
      " The program aims to provide comprehensive training that combines modules in mathematics/statistics, computer science, and artificial intelligence. It aims to equip students with the skills demanded by the job market to manage and analyze data, including concepts such as exploratory data analysis, statistical inference and modeling, machine learning, and high-dimensional data analysis. \n",
      "\n",
      "You: Where can I find information about school clubs?\n",
      "\n",
      " You can find information about school clubs in the 'Clubs and Student Organizations' section. This section lists available clubs, their descriptions, meeting times, and contact information for club leaders or advisors. You can explore different clubs and decide which ones interest you the most. \n",
      "\n",
      "You: Are school events open only to school students, or we can invite external friends?\n",
      "\n",
      " Most school events are primarily intended for students and staff of the school. However, some events may be open to external guests, including friends from other schools or the community. The accessibility of events to external guests depends on the specific event and its organizers. You can usually find details about invitation policies and invitations in event announcements or by contacting the event organizers. \n",
      "\n",
      "You: Does the school guarantee us free access to online courses and certifications?\n",
      "\n",
      " The school collaborates with some major companies and organizations to offer certification programs and opportunities to students. These programs may provide certifications in various fields, including computer science. Eligibility and availability of free certifications may vary, so it's advisable to check with your academic department or the career services office for more information on current opportunities. \n",
      "\n",
      "You: What fields are available in the doctoral cycle?\n",
      "\n",
      " Currently, our school offers two doctoral programs: the first one is Computer Science and Data Science; This program focuses on the areas of computer science, data analysis, and information. The second one is Information, Documentation, Knowledge, and Society; This program focuses on the fields of information, documentation, knowledge management, and information society. You'll have the opportunity to explore topics related to information management and the impact of the information society. \n",
      "\n",
      "You: Thanks for the help!\n",
      "\n",
      " You're welcome. If you have more questions in the future, don't hesitate to contact us. Good luck with your studies! \n",
      "\n",
      "You: quit\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello! I am here to chat. if you need to go just enter \\\"quit\\\" :)\")            \n",
    "while True:\n",
    "    input_data = input(\"You: \")\n",
    "    if input_data.lower() in [\"exit\", \"quit\", \"stop\", \"bye\", \"leave\",\"goodbye\", \"good bye\", \"see you later\"]:\n",
    "        print(\"Goodbye!\")\n",
    "        break  # Exit the while loop\n",
    "    answer = response(input_data)\n",
    "    answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ec171b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
